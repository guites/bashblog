<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
<channel><title>Blog do guilherme</title><link>https://guilhermegarcia.dev/blog/index.html</link>
<description>programação e outras coisas menos úteis</description><language>pt-br</language>
<lastBuildDate>Mon, 20 Mar 2023 21:57:28 -0300</lastBuildDate>
<pubDate>Mon, 20 Mar 2023 21:57:28 -0300</pubDate>
<atom:link href="https://guilhermegarcia.dev/blog/feed.rss" rel="self" type="application/rss+xml" />
<item><title>
Análise de conteúdo tabnews (fevereiro de 2023)
</title><description><![CDATA[

<p>Há um tempo descobri o site <a href="https://tabnews.com.br">tabnews</a>, uma espécie de agregador de notícias/rede social focada em tópicos de programação e tecnologia. É uma iniciativa do filipe deschamps, mas está sendo desenvolvido de forma comunitária através do seu <a href="https://github.com/filipedeschamps/tabnews.com.br">repositório do github</a>.</p>

<p>Dando uma explorada nos conteúdos reparei que as postagens costumam focar em tópicos como estudos e aprendizagem, busca de empregos, uso de inteligência artifical, projetos pessoais e notícias de tecnologia no geral.</p>

<p>Fiquei curioso sobre quais assuntos são mais populares e quais outros insights podemos ter sobre o conteúdo publicado na plataforma, então decidi fazer um levantamento dos dados existentes, visto que a API é aberta ao público :).</p>

<p>Optei por restringir a análise ao mês de fevereiro de 2023, onde o conjunto de dados é recente, mas não tem um tamanho que dificulte a manipulação.</p>

<p>Você pode acessar o código completo <a href="https://www.kaggle.com/guites/tabnews-analysis-february-2023">neste notebook do kaggle</a>.</p>

<h2>Coleta de dados no intervalo 02/2023 até 03/2023</h2>

<p>Existe um <a href="https://www.tabnews.com.br/GabrielSozinho/documentacao-da-api-do-tabnews">post</a> de referência como documentação da API. Usando ele como base, e tentando interpretar o <a href="https://github.com/filipedeschamps/tabnews.com.br/tree/main/pages/api/v1">código fonte</a> dos endpoints, descobri o seguinte:</p>

<ol>
<li>A URL base para listar as postagens é <a href="https://www.tabnews.com.br/api/v1/contents">https://www.tabnews.com.br/api/v1/contents</a>;</li>
<li>Os posts podem ser ordenados de acordo com três estratégias: "new", "old" e "relevant"
<ol>
<li>"new" aplica um <code>ORDER BY published_at DESC</code>: mostra os posts mais recentes primeiro;</li>
<li>"old" aplica um <code>ORDER BY published_at ASC</code>: mostra os posts mais antigos primeiro;</li>
<li>"relevant" aplica um critério um pouco mais complexo, levando em conta o tempo de existência do post, o número de <em>tabcoins</em> (tipo um upvote da plataforma) e algumas outras regrinhas(ver <a href="https://github.com/filipedeschamps/tabnews.com.br/blob/main/models/content.js#L914"><code>getContentScore</code></a>);</li>
</ol></li>
<li>O máximo de postagens retornadas por vez é 100;</li>
<li>Não existe um filtro específico por data;</li>
<li>Existem alguns cabeçalhos (<code>X-Pagination-Total-Rows</code> e <code>Link</code>) que auxiliam na navegação;</li>
<li>Existe um <a href="https://github.com/filipedeschamps/tabnews.com.br/blob/main/pages/api/v1/analytics/root-content-published/index.public.js">endpoint</a> que retorna o número de postagens por dia num intervalo de 2 meses da data atual;</li>
</ol>

<p>Vamos verificar o formato de um request básico, passando <code>new</code> como estratégia de ordenação.</p>

<pre><code>$ curl -I "https://www.tabnews.com.br/api/v1/contents?strategy=new"
HTTP/2 200
...
..
link: &lt;https://www.tabnews.com.br/api/v1/contents?strategy=new&amp;page=1&amp;per_page=1&gt;; rel="first", &lt;https://www.tabnews.com.br/api/v1/contents?strategy=new&amp;page=2&amp;per_page=1&gt;; rel="next", &lt;https://www.tabnews.com.br/api/v1/contents?strategy=new&amp;page=8153&amp;per_page=1&gt;; rel="last"
x-pagination-total-rows: 8153
...
..
</code></pre>

<p>De acordo com o cabeçalho <code>x-pagination-total-rows</code>, temos um total de 8153 postagens. Podemos combinar essa informação com o número de posts por dia para descobrir quando começam os posts de fevereiro de 2023.</p>

<pre><code>$ curl https://www.tabnews.com.br/api/v1/analytics/root-content-published
[
    {"date":"13/01","conteudos":38},
    {"date":"14/01","conteudos":29},
    {"date":"15/01","conteudos":30},
    {"date":"16/01","conteudos":50},
    {"date":"17/01","conteudos":37},
    {"date":"18/01","conteudos":44},
    ..
]
</code></pre>

<p>Podemos roubar aqui e selecionar apenas os valores partindo de 01/02, para somá-los com um filtro.</p>

<pre><code>$ echo '[{"date":"01/02","conteudos":46},{"date":"02/02","conteudos":66},{"date":"03/02","conteudos":43},{"date":"04/02","conteudos":43},{"date":"05/02","conteudos":31},{"date":"06/02","conteudos":55},{"date":"07/02","conteudos":51},{"date":"08/02","conteudos":46},{"date":"09/02","conteudos":47},{"date":"10/02","conteudos":39},{"date":"11/02","conteudos":18},{"date":"12/02","conteudos":19},{"date":"13/02","conteudos":40},{"date":"14/02","conteudos":29},{"date":"15/02","conteudos":45},{"date":"16/02","conteudos":54},{"date":"17/02","conteudos":48},{"date":"18/02","conteudos":21},{"date":"19/02","conteudos":18},{"date":"20/02","conteudos":27},{"date":"21/02","conteudos":27},{"date":"22/02","conteudos":37},{"date":"23/02","conteudos":38},{"date":"24/02","conteudos":41},{"date":"25/02","conteudos":10},{"date":"26/02","conteudos":13},{"date":"27/02","conteudos":51},{"date":"28/02","conteudos":38},{"date":"01/03","conteudos":21},{"date":"02/03","conteudos":35},{"date":"03/03","conteudos":35},{"date":"04/03","conteudos":21},{"date":"05/03","conteudos":15},{"date":"06/03","conteudos":28},{"date":"07/03","conteudos":27},{"date":"08/03","conteudos":40},{"date":"09/03","conteudos":37},{"date":"10/03","conteudos":31},{"date":"11/03","conteudos":29},{"date":"12/03","conteudos":23},{"date":"13/03","conteudos":34}]' \
| jq "[.[].conteudos] | add"
1417
</code></pre>

<p>1417! Esse é o número de postagens criadas des do início de fevereiro, até o dia atual.</p>

<p>1417 postagens / 100 posts por página ≈ 14 páginas: iniciamos as requisições na página 68 (82-14), onde deve estar o primeiro post de fevereiro, e vamos avançando até chegar no dia 28.</p>

<h3>Automatizando o processo</h3>

<p>Um script em python vai nos ajudar a salvar os dados pra consulta futura.</p>

<p>A lógica é simples: fazer requisições na API partindo da página 68, salvando os resultados, e indo para a próxima página até atingirmos o primeiro post datado de março.</p>

<pre><code>request_loop = True # variável que define se devemos seguir para a próxima página
february_posts = [] # lista que vai segurar todas as postagens

base_url = "https://www.tabnews.com.br/api/v1"
current_page = 68 # variável que segura o valor da página atual

while request_loop:
    # concatenamos a url atual baseada no valor da página atual
    request_url = f"{base_url}/contents?strategy=old&amp;page={current_page}&amp;per_page=100"
    r = requests.get(request_url)
    posts = r.json()
    for post in posts:

        # caso o post atual for de antes de fevereiro, passamos para o próximo
        if published_before_february(post):
            continue

        # caso o post atual tiver a data de publicação maior que fevereiro
        # chegou a hora de parar nossa busca!
        if published_after_february(post):
            request_loop = False
            break

        february_posts.append(post)

    # incrementamos o contador, indo para a próxima página
    current_page = current_page + 1

    sleep(1)  # damos uma segurada pra não abusar do servidor :')

with open("february.json", "w") as outfile:
    json.dump(february_posts, outfile)
</code></pre>

<p>O código acima vai ir de página em página (com 100 posts por página), partindo da 68 e aumentando sempre, até chegarmos no primeiro post de março. Nesse momento o loop acaba (a variável <code>request_loop</code> se torna <code>False</code>), e nós salvamos os posts no arquivo <code>february_posts.json</code>.</p>

<p>As funções <code>published_before_february</code> e <code>published_after_february</code> verificam se a data de publicação é anterior ou posterior a fevereiro, respectivamente:</p>

<pre><code>    def published_before_february(request_body):
        """Returns whether the given post was `published_at` before 01/02/2023"""
        published_at = dt.strptime(request_body["published_at"], "%Y-%m-%dT%H:%M:%S.%fZ")
        return dt.strptime("2023-02-01", "%Y-%m-%d") &gt; published_at


    def published_after_february(request_body):
        """Returns whether the given post was `published_at` after 28/02/2023"""
        published_at = dt.strptime(request_body["published_at"], "%Y-%m-%dT%H:%M:%S.%fZ")
        return published_at &gt; dt.strptime("2023-02-28T23:59:59", "%Y-%m-%dT%H:%M:%S")
</code></pre>

<p>Com isso, vamos acumular todos os posts do mês de fevereiro para iniciar nossa análise.</p>

<p><details><summary>Clique aqui para visualizar o script inteiro (40 linhas, ❤️ python)</summary></p>

<pre><code>import json
import requests

from datetime import datetime as dt
from time import sleep


def published_before_february(request_body):
    """Returns whether the given post was `published_at` before 01/02/2023"""
    published_at = dt.strptime(request_body["published_at"], "%Y-%m-%dT%H:%M:%S.%fZ")
    return dt.strptime("2023-02-01", "%Y-%m-%d") &gt; published_at


def published_after_february(request_body):
    """Returns whether the given post was `published_at` after 28/02/2023"""
    published_at = dt.strptime(request_body["published_at"], "%Y-%m-%dT%H:%M:%S.%fZ")
    return published_at &gt; dt.strptime("2023-02-28T23:59:59", "%Y-%m-%dT%H:%M:%S")


base_url = "https://www.tabnews.com.br/api/v1"
current_page = 68

request_loop = True

february_posts = []
while request_loop:
    request_url = f"{base_url}/contents?strategy=old&amp;page={current_page}&amp;per_page=100"
    r = requests.get(request_url)
    posts = r.json()
    for post in posts:
        if published_before_february(post):
            continue
        if published_after_february(post):
            request_loop = False
            break
        february_posts.append(post)
    current_page = current_page + 1
    sleep(1)  # prevent abuse :')

with open("february.json", "w") as outfile:
    json.dump(february_posts, outfile)
</code></pre>

<p></details></p>

<p><aside>Caso você rodar esse script no futuro, a página inicial provavelmente vai ser muito maior que a 68.</aside></p>

<h2>Análises iniciais</h2>

<p>Vamos começar carregando o arquivo json como um dataframe.</p>

<pre><code>df = pd.read_json("./february.json")
</code></pre>

<p>Com isso, podemos pegar algumas informações básicas.</p>

<pre><code>$ df.shape
(935, 14)
</code></pre>

<p><strong>Foram publicados 935 posts em fevereiro</strong>.</p>

<pre><code>df.head()
</code></pre>

<div class="table-wrapper">
<table class="dataframe" border="1">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>owner_id</th>
      <th>parent_id</th>
      <th>slug</th>
      <th>title</th>
      <th>status</th>
      <th>source_url</th>
      <th>created_at</th>
      <th>updated_at</th>
      <th>published_at</th>
      <th>deleted_at</th>
      <th>owner_username</th>
      <th>tabcoins</th>
      <th>children_deep_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6190e4fe-4aa3-4557-b69a-f42ac8765715</td>
      <td>6e750ada-d106-4a6f-bd1e-c4c5a9d3b7f6</td>
      <td>NaN</td>
      <td>imersao-dev-aula-1-expandindo-os-conhecimentos</td>
      <td>Imersão Dev - Aula 1 | Expandindo os Conhecime...</td>
      <td>published</td>
      <td>None</td>
      <td>2023-02-01 00:14:05.031000+00:00</td>
      <td>2023-02-01 00:14:23.724000+00:00</td>
      <td>2023-02-01 00:14:05.054000+00:00</td>
      <td>NaT</td>
      <td>TheDevick</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>c2347a33-28dd-4c03-9127-012d9b61cd82</td>
      <td>f6b5df28-4810-4f94-a523-53be17fffbc6</td>
      <td>NaN</td>
      <td>desenvolvedor-react-em-inicio-de-carreira</td>
      <td>Desenvolvedor React em início de carreira</td>
      <td>published</td>
      <td>None</td>
      <td>2023-02-01 00:24:06.513000+00:00</td>
      <td>2023-02-01 00:24:06.513000+00:00</td>
      <td>2023-02-01 00:24:06.537000+00:00</td>
      <td>NaT</td>
      <td>kevensouzz</td>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>447f4db9-9570-4b29-bce5-48c3195879e1</td>
      <td>c8a4bd72-1edd-4ca4-96b6-0310d0f53457</td>
      <td>NaN</td>
      <td>10-dicas-simples-para-melhorar-como-programado...</td>
      <td>10 dicas simples para melhorar como programado...</td>
      <td>published</td>
      <td>None</td>
      <td>2023-02-01 00:45:36.751000+00:00</td>
      <td>2023-02-01 00:49:18.821000+00:00</td>
      <td>2023-02-01 00:45:36.761000+00:00</td>
      <td>NaT</td>
      <td>roneydc</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6c0744af-c140-4915-ac3c-d73cc0e53f9a</td>
      <td>c8a4bd72-1edd-4ca4-96b6-0310d0f53457</td>
      <td>NaN</td>
      <td>vamos-falar-sobre-linguangem-orientadas-a-objetos</td>
      <td>1 - Vamos falar sobre linguangem orientada a o...</td>
      <td>published</td>
      <td>None</td>
      <td>2023-02-01 00:56:42.619000+00:00</td>
      <td>2023-02-01 01:08:07.698000+00:00</td>
      <td>2023-02-01 00:56:42.643000+00:00</td>
      <td>NaT</td>
      <td>roneydc</td>
      <td>-1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>05a8f1e2-4bc5-4a9f-861b-8fcb64e8689f</td>
      <td>c8a4bd72-1edd-4ca4-96b6-0310d0f53457</td>
      <td>NaN</td>
      <td>2-um-pequeno-exemplo-de-orientacao-a-objeto-py...</td>
      <td>2 - Um pequeno exemplo de orientação a objeto ...</td>
      <td>published</td>
      <td>None</td>
      <td>2023-02-01 01:07:57.037000+00:00</td>
      <td>2023-02-01 01:07:57.037000+00:00</td>
      <td>2023-02-01 01:07:57.051000+00:00</td>
      <td>NaT</td>
      <td>roneydc</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<h3>Limpando os dados</h3>

<p>Existe uma conta, <a href="https://www.tabnews.com.br/NewsletterOficial">NewsletterOficial</a> que faz postagens regulares de notícias de outros sites. Como a ideia é entender o relacionamento entre usuários, vamos remover os posts da Newsletter do nosso dataset.</p>

<pre><code>df = df.query('owner_username != "NewsletterOficial"')
</code></pre>

<p>Para facilitar a identificação, vamos remover algumas colunas que não são de interesse (id, owner_id, parent_id, status, created_at, updated_at, deleted_at).</p>

<pre><code>df = df[[
    #'id',
    #'owner_id',
    #'parent_id',
    'slug',
    'title',
    #'status',
    'source_url',
    #'created_at',
    #'updated_at',
    'published_at',
    #'deleted_at',
    'owner_username',
    'tabcoins',
    'children_deep_count'
]]
</code></pre>

<p>Vamos aproveitar pra renomear a coluna "children_deep_count" para "comments" e a coluna "owner_username" para "username".</p>

<pre><code>df = df.rename(
    columns={
        'children_deep_count':'comments',
        'owner_username': 'username'
    }
)
</code></pre>

<p>Vamos puxar uma descrição básica do nosso dataset:</p>

<pre><code>df.describe()
</code></pre>

<div class="table-wrapper">
    <table class="dataframe" border="1">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>parent_id</th>
          <th>tabcoins</th>
          <th>comments</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>count</th>
          <td>0.0</td>
          <td>795.000000</td>
          <td>795.000000</td>
        </tr>
        <tr>
          <th>mean</th>
          <td>NaN</td>
          <td>3.373585</td>
          <td>5.596226</td>
        </tr>
        <tr>
          <th>std</th>
          <td>NaN</td>
          <td>7.522933</td>
          <td>13.093704</td>
        </tr>
        <tr>
          <th>min</th>
          <td>NaN</td>
          <td>-12.000000</td>
          <td>0.000000</td>
        </tr>
        <tr>
          <th>25%</th>
          <td>NaN</td>
          <td>1.000000</td>
          <td>1.000000</td>
        </tr>
        <tr>
          <th>50%</th>
          <td>NaN</td>
          <td>1.000000</td>
          <td>3.000000</td>
        </tr>
        <tr>
          <th>75%</th>
          <td>NaN</td>
          <td>3.000000</td>
          <td>6.000000</td>
        </tr>
        <tr>
          <th>max</th>
          <td>NaN</td>
          <td>82.000000</td>
          <td>301.000000</td>
        </tr>
      </tbody>
    </table>
</div>

<p>Nos restam <strong>795 posts criados por usuários normais</strong>.</p>

<p><strong>A metade das postagens (50%) não atinge mais de três comentário.</strong></p>

<p><strong>Três quartos das postagens (75%) não atinge 3 tabcoins</strong>! Levando em conta que todo post "nasce" com 1 tabcoin, a vaca tá magra.</p>

<p>Vamos descobrir o valor total de comentários realizados e o total de tabcoins recebidos pelas postagens do mês.</p>

<pre><code>$ print(f"Total de tabcoins recebidos: {df['tabcoins'].sum()}\nTotal de comentários realizados: {df['comments'].sum()}")
</code></pre>

<p>Total de tabcoins recebidos: <strong>2682</strong></p>

<p>Total de comentários realizados: <strong>4449</strong></p>

<h3>Distribuição de comentários</h3>

<p>Quantos posts tiveram pelo menos um comentário?</p>

<pre><code>$ df.query('comments &gt; 0')['comments'].count()
636
</code></pre>

<p><strong>80% das postagens receberam ao menos um comentário</strong>!</p>

<p>Qual a distribuição de comentários por post?</p>

<pre><code>comments_distrib = pd.DataFrame(
    df.groupby(['comments'])['comments'] \
    .count()
).rename(columns={"comments": "num_posts"}) \
.reset_index()
</code></pre>

<p>Vamos agrupar nosso dataset pelo número de comentários, e verificar o percentual de cada um em relação ao número total de postagens.</p>

<pre><code>comments_distrib['percent_posts'] = (comments_distrib['num_posts'] / 795) * 100
</code></pre>

<p>Outra relação interessante é quantos % dos comentários do site se encontram nesses posts.</p>

<p>Por exemplo, quantos porcento dos comentários totais foram feitos em posts com 2, 3 ou 5 comentários?</p>

<pre><code>comments_distrib['percent_comments'] = ((comments_distrib['comments'] * comments_distrib['num_posts']) / 4449) * 100
</code></pre>

<p>Vamos adicionar também um contador com o total de comentários pra cada número de comentários.</p>

<pre><code>comments_distrib['total_comments'] = comments_distrib['num_posts'] * comments_distrib['comments']
</code></pre>

<p>Vamos usar uma função para formatar os valores percentuais com duas casas decimais.</p>

<pre><code>def format_two_decimals(x):
    return float("%.2f" % x);

comments_distrib['percent_posts'] = comments_distrib['percent_posts'].apply(format_two_decimals)
comments_distrib['percent_comments'] = comments_distrib['percent_comments'].apply(format_two_decimals)
</code></pre>

<div class="table-wrapper">
<table class="dataframe" border="1">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>comments</th>
      <th>num_posts</th>
      <th>total_comments</th>
      <th>percent_posts</th>
      <th>percent_comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>41</th>
      <td>301</td>
      <td>1</td>
      <td>301</td>
      <td>0.13</td>
      <td>6.77</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>69</td>
      <td>276</td>
      <td>8.68</td>
      <td>6.20</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>42</td>
      <td>252</td>
      <td>5.28</td>
      <td>5.66</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>49</td>
      <td>245</td>
      <td>6.16</td>
      <td>5.51</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>117</td>
      <td>234</td>
      <td>14.72</td>
      <td>5.26</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>77</td>
      <td>231</td>
      <td>9.69</td>
      <td>5.19</td>
    </tr>
    <tr>
      <th>7</th>
      <td>7</td>
      <td>32</td>
      <td>224</td>
      <td>4.03</td>
      <td>5.03</td>
    </tr>
    <tr>
      <th>8</th>
      <td>8</td>
      <td>28</td>
      <td>224</td>
      <td>3.52</td>
      <td>5.03</td>
    </tr>
    <tr>
      <th>10</th>
      <td>10</td>
      <td>18</td>
      <td>180</td>
      <td>2.26</td>
      <td>4.05</td>
    </tr>
    <tr>
      <th>9</th>
      <td>9</td>
      <td>18</td>
      <td>162</td>
      <td>2.26</td>
      <td>3.64</td>
    </tr>
    <tr>
      <th>11</th>
      <td>11</td>
      <td>14</td>
      <td>154</td>
      <td>1.76</td>
      <td>3.46</td>
    </tr>
    <tr>
      <th>12</th>
      <td>12</td>
      <td>11</td>
      <td>132</td>
      <td>1.38</td>
      <td>2.97</td>
    </tr>
    <tr>
      <th>13</th>
      <td>13</td>
      <td>9</td>
      <td>117</td>
      <td>1.13</td>
      <td>2.63</td>
    </tr>
    <tr>
      <th>25</th>
      <td>25</td>
      <td>4</td>
      <td>100</td>
      <td>0.50</td>
      <td>2.25</td>
    </tr>
    <tr>
      <th>20</th>
      <td>20</td>
      <td>5</td>
      <td>100</td>
      <td>0.63</td>
      <td>2.25</td>
    </tr>
    <tr>
      <th>14</th>
      <td>14</td>
      <td>7</td>
      <td>98</td>
      <td>0.88</td>
      <td>2.20</td>
    </tr>
    <tr>
      <th>16</th>
      <td>16</td>
      <td>6</td>
      <td>96</td>
      <td>0.75</td>
      <td>2.16</td>
    </tr>
    <tr>
      <th>18</th>
      <td>18</td>
      <td>5</td>
      <td>90</td>
      <td>0.63</td>
      <td>2.02</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>87</td>
      <td>87</td>
      <td>10.94</td>
      <td>1.96</td>
    </tr>
    <tr>
      <th>40</th>
      <td>84</td>
      <td>1</td>
      <td>84</td>
      <td>0.13</td>
      <td>1.89</td>
    </tr>
    <tr>
      <th>26</th>
      <td>26</td>
      <td>3</td>
      <td>78</td>
      <td>0.38</td>
      <td>1.75</td>
    </tr>
    <tr>
      <th>39</th>
      <td>76</td>
      <td>1</td>
      <td>76</td>
      <td>0.13</td>
      <td>1.71</td>
    </tr>
    <tr>
      <th>33</th>
      <td>36</td>
      <td>2</td>
      <td>72</td>
      <td>0.25</td>
      <td>1.62</td>
    </tr>
    <tr>
      <th>24</th>
      <td>24</td>
      <td>3</td>
      <td>72</td>
      <td>0.38</td>
      <td>1.62</td>
    </tr>
    <tr>
      <th>38</th>
      <td>71</td>
      <td>1</td>
      <td>71</td>
      <td>0.13</td>
      <td>1.60</td>
    </tr>
    <tr>
      <th>32</th>
      <td>35</td>
      <td>2</td>
      <td>70</td>
      <td>0.25</td>
      <td>1.57</td>
    </tr>
    <tr>
      <th>31</th>
      <td>32</td>
      <td>2</td>
      <td>64</td>
      <td>0.25</td>
      <td>1.44</td>
    </tr>
    <tr>
      <th>29</th>
      <td>30</td>
      <td>2</td>
      <td>60</td>
      <td>0.25</td>
      <td>1.35</td>
    </tr>
    <tr>
      <th>15</th>
      <td>15</td>
      <td>4</td>
      <td>60</td>
      <td>0.50</td>
      <td>1.35</td>
    </tr>
    <tr>
      <th>23</th>
      <td>23</td>
      <td>2</td>
      <td>46</td>
      <td>0.25</td>
      <td>1.03</td>
    </tr>
    <tr>
      <th>22</th>
      <td>22</td>
      <td>2</td>
      <td>44</td>
      <td>0.25</td>
      <td>0.99</td>
    </tr>
    <tr>
      <th>37</th>
      <td>44</td>
      <td>1</td>
      <td>44</td>
      <td>0.13</td>
      <td>0.99</td>
    </tr>
    <tr>
      <th>36</th>
      <td>43</td>
      <td>1</td>
      <td>43</td>
      <td>0.13</td>
      <td>0.97</td>
    </tr>
    <tr>
      <th>35</th>
      <td>42</td>
      <td>1</td>
      <td>42</td>
      <td>0.13</td>
      <td>0.94</td>
    </tr>
    <tr>
      <th>34</th>
      <td>41</td>
      <td>1</td>
      <td>41</td>
      <td>0.13</td>
      <td>0.92</td>
    </tr>
    <tr>
      <th>19</th>
      <td>19</td>
      <td>2</td>
      <td>38</td>
      <td>0.25</td>
      <td>0.85</td>
    </tr>
    <tr>
      <th>17</th>
      <td>17</td>
      <td>2</td>
      <td>34</td>
      <td>0.25</td>
      <td>0.76</td>
    </tr>
    <tr>
      <th>30</th>
      <td>31</td>
      <td>1</td>
      <td>31</td>
      <td>0.13</td>
      <td>0.70</td>
    </tr>
    <tr>
      <th>28</th>
      <td>28</td>
      <td>1</td>
      <td>28</td>
      <td>0.13</td>
      <td>0.63</td>
    </tr>
    <tr>
      <th>27</th>
      <td>27</td>
      <td>1</td>
      <td>27</td>
      <td>0.13</td>
      <td>0.61</td>
    </tr>
    <tr>
      <th>21</th>
      <td>21</td>
      <td>1</td>
      <td>21</td>
      <td>0.13</td>
      <td>0.47</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>159</td>
      <td>0</td>
      <td>20.00</td>
      <td>0.00</td>
    </tr>
  </tbody>
</table>
</div>

<p>Existe uma grande concentração de comentários em poucos posts. Se ordenarmos pelo número de comentários por post, os que possuem maior número de comentário tem baixa ocorrência (como é de se esperar).</p>

<pre><code>comments_distrib.sort_values(by=['comments'], ascending=False).head(10)
</code></pre>

<div class="table-wrapper">
<table class="dataframe" border="1">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>comments</th>
      <th>num_posts</th>
      <th>total_comments</th>
      <th>percent_posts</th>
      <th>percent_comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>41</th>
      <td>301</td>
      <td>1</td>
      <td>301</td>
      <td>0.13</td>
      <td>6.77</td>
    </tr>
    <tr>
      <th>40</th>
      <td>84</td>
      <td>1</td>
      <td>84</td>
      <td>0.13</td>
      <td>1.89</td>
    </tr>
    <tr>
      <th>39</th>
      <td>76</td>
      <td>1</td>
      <td>76</td>
      <td>0.13</td>
      <td>1.71</td>
    </tr>
    <tr>
      <th>38</th>
      <td>71</td>
      <td>1</td>
      <td>71</td>
      <td>0.13</td>
      <td>1.60</td>
    </tr>
    <tr>
      <th>37</th>
      <td>44</td>
      <td>1</td>
      <td>44</td>
      <td>0.13</td>
      <td>0.99</td>
    </tr>
    <tr>
      <th>36</th>
      <td>43</td>
      <td>1</td>
      <td>43</td>
      <td>0.13</td>
      <td>0.97</td>
    </tr>
    <tr>
      <th>35</th>
      <td>42</td>
      <td>1</td>
      <td>42</td>
      <td>0.13</td>
      <td>0.94</td>
    </tr>
    <tr>
      <th>34</th>
      <td>41</td>
      <td>1</td>
      <td>41</td>
      <td>0.13</td>
      <td>0.92</td>
    </tr>
    <tr>
      <th>33</th>
      <td>36</td>
      <td>2</td>
      <td>72</td>
      <td>0.25</td>
      <td>1.62</td>
    </tr>
    <tr>
      <th>32</th>
      <td>35</td>
      <td>2</td>
      <td>70</td>
      <td>0.25</td>
      <td>1.57</td>
    </tr>
  </tbody>
</table>
</div>

<p>Podemos agrupar pelo número de ocorrências (<code>num_posts</code>) para entender como esses posts populares impactam no conteúdo produzido pela plataforma.</p>

<pre><code>comments_by_num_posts = comments_distrib.groupby('num_posts') \
.agg(
    {
        'num_posts': 'sum',
        'percent_posts': 'sum',
        'percent_comments': 'sum',
        'comments': 'sum',
        'total_comments': 'sum',
    }
) \
.rename(columns={'num_posts': 'total_posts'}) \
.reset_index(drop=False) \
.sort_values(by=['comments'], ascending=False)
print(comments_by_num_posts)
</code></pre>

<div class="table-wrapper">
<table class="dataframe" border="1">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num_posts</th>
      <th>total_posts</th>
      <th>percent_posts</th>
      <th>percent_comments</th>
      <th>comments</th>
      <th>total_comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>12</td>
      <td>1.56</td>
      <td>18.20</td>
      <td>809</td>
      <td>809</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>16</td>
      <td>2.00</td>
      <td>9.61</td>
      <td>214</td>
      <td>428</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>6</td>
      <td>0.76</td>
      <td>3.37</td>
      <td>50</td>
      <td>150</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>8</td>
      <td>1.00</td>
      <td>3.60</td>
      <td>40</td>
      <td>160</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>10</td>
      <td>1.26</td>
      <td>4.27</td>
      <td>38</td>
      <td>190</td>
    </tr>
    <tr>
      <th>10</th>
      <td>18</td>
      <td>36</td>
      <td>4.52</td>
      <td>7.69</td>
      <td>19</td>
      <td>342</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>6</td>
      <td>0.75</td>
      <td>2.16</td>
      <td>16</td>
      <td>96</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>7</td>
      <td>0.88</td>
      <td>2.20</td>
      <td>14</td>
      <td>98</td>
    </tr>
    <tr>
      <th>7</th>
      <td>9</td>
      <td>9</td>
      <td>1.13</td>
      <td>2.63</td>
      <td>13</td>
      <td>117</td>
    </tr>
    <tr>
      <th>8</th>
      <td>11</td>
      <td>11</td>
      <td>1.38</td>
      <td>2.97</td>
      <td>12</td>
      <td>132</td>
    </tr>
    <tr>
      <th>9</th>
      <td>14</td>
      <td>14</td>
      <td>1.76</td>
      <td>3.46</td>
      <td>11</td>
      <td>154</td>
    </tr>
    <tr>
      <th>11</th>
      <td>28</td>
      <td>28</td>
      <td>3.52</td>
      <td>5.03</td>
      <td>8</td>
      <td>224</td>
    </tr>
    <tr>
      <th>12</th>
      <td>32</td>
      <td>32</td>
      <td>4.03</td>
      <td>5.03</td>
      <td>7</td>
      <td>224</td>
    </tr>
    <tr>
      <th>13</th>
      <td>42</td>
      <td>42</td>
      <td>5.28</td>
      <td>5.66</td>
      <td>6</td>
      <td>252</td>
    </tr>
    <tr>
      <th>14</th>
      <td>49</td>
      <td>49</td>
      <td>6.16</td>
      <td>5.51</td>
      <td>5</td>
      <td>245</td>
    </tr>
    <tr>
      <th>15</th>
      <td>69</td>
      <td>69</td>
      <td>8.68</td>
      <td>6.20</td>
      <td>4</td>
      <td>276</td>
    </tr>
    <tr>
      <th>16</th>
      <td>77</td>
      <td>77</td>
      <td>9.69</td>
      <td>5.19</td>
      <td>3</td>
      <td>231</td>
    </tr>
    <tr>
      <th>18</th>
      <td>117</td>
      <td>117</td>
      <td>14.72</td>
      <td>5.26</td>
      <td>2</td>
      <td>234</td>
    </tr>
    <tr>
      <th>17</th>
      <td>87</td>
      <td>87</td>
      <td>10.94</td>
      <td>1.96</td>
      <td>1</td>
      <td>87</td>
    </tr>
    <tr>
      <th>19</th>
      <td>159</td>
      <td>159</td>
      <td>20.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<p>Podemos ver que <strong>18.2% dos comentários ficaram acumulados em menos de 2% das postagens</strong>.</p>

<p>Esse acumulo de comentários pode ser visualizado plotando o percentual de posts pelo percentual de comentários.</p>

<pre><code>comments_by_num_posts.sort_values(by=['percent_posts']).plot(kind='bar', x='percent_posts', y='percent_comments', title='Percentual de Posts vs Percentual de Comentários')
plt.show()
</code></pre>

<p><img src="./imgs/pct_posts_pct_comments-fs8.png" alt="percentual de postagens com percentual de comentários" title="percentual de postagens com percentual de comentários" /></p>

<h2>Encontrando tags nas postagens</h2>

<p>O Tabnews utiliza um sistema onde o pessoal <em>taggeia</em> seus posts manualmente, usando colchetes ou <code>categoria: título do post</code>.</p>

<p><strong>Quais foram as tags mais utilizadas?</strong></p>

<p>Vamos iterar sobre os posts e criar uma nova coluna "tags" extraindo os valores dos títulos que estiverem nos dois formatos listados acima.</p>

<pre><code>def find_tags(row):
    title = row['title']
    has_tag = re.search("^.*:", title)
    has_colchete_tags = re.search("\[.*\]", title)
    if has_tag:
        return has_tag.group(0)
    elif has_colchete_tags:
        return has_colchete_tags.group(0)
    return ""

df['tags'] = df.apply(find_tags, axis=1)
df.query('tags != ""')[['title', 'tags']]
</code></pre>

<div class="table-wrapper">
<table class="dataframe" border="1">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>tags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>8</th>
      <td>Ler documentação: como isso me ajudou a progra...</td>
      <td>Ler documentação:</td>
    </tr>
    <tr>
      <th>11</th>
      <td>[DICA] Tabela de nomes curtos para variáveis l...</td>
      <td>[DICA]</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Compreendendo o CSS: A Linguagem de estilo par...</td>
      <td>Compreendendo o CSS:</td>
    </tr>
    <tr>
      <th>24</th>
      <td>[Ajuda] Api para finança eur/usd</td>
      <td>[Ajuda]</td>
    </tr>
    <tr>
      <th>26</th>
      <td>[JS] Problema ao movimentar o jogador pelo &lt;ca...</td>
      <td>[JS]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>909</th>
      <td>Pitch: Como eu e meu colega de time estamos es...</td>
      <td>Pitch:</td>
    </tr>
    <tr>
      <th>921</th>
      <td>Abordagem de humor, mas crítica, sobre a adoçã...</td>
      <td>[Vídeo]</td>
    </tr>
    <tr>
      <th>922</th>
      <td>O chatbot que nunca entende: como depurar um m...</td>
      <td>O chatbot que nunca entende:</td>
    </tr>
    <tr>
      <th>925</th>
      <td>Konsta UI: replicação "Pixel Perfect" de iOS e...</td>
      <td>Konsta UI:</td>
    </tr>
    <tr>
      <th>929</th>
      <td>Redis vs. outros bancos de dados NoSQL: Prós e...</td>
      <td>Redis vs. outros bancos de dados NoSQL:</td>
    </tr>
  </tbody>
</table>
<p>201 rows  x 2 columns</p>
</div>

<p><strong>201</strong> posts parecem ter algum tipo de tag no título.</p>

<p>Parece que muitos usuários usam os dois pontos (<code>:</code>) sem o intuito de tag.</p>

<p>Vamos limpar as tags encontradas e verificar se existe algum padrão.</p>

<p>Pra isso, instalamos o pacote <code>unidecode</code>, que remove acentos, cedilhas e outros caracteres especiaisporpadrão.</p>

<pre><code>!pip install unidecode --quiet
from unidecode import unidecode
</code></pre>

<p>Depois, vamos aplicar mais um filtro na coluna <code>tags</code>.</p>

<pre><code># remover acentos, símbolos e mesclar minusculas com maíusculas
def strip_func(row):
    tags = row['tags']
    if tags == "":
        return tags
    rm_symbols = [',', '!', '.', ';', '[', ']', ':']
    tags = unidecode(tags).lower()
    return tags.translate({ord(x): '' for x in rm_symbols})

df['tags'] = df.apply(strip_func, axis=1)
</code></pre>

<p>Algumas tags parecem populares:</p>

<pre><code>df.query('tags != ""') \
.groupby('tags') \
.count() \
.sort_values(
    by=['title'],
    ascending=False
) \
.head(10)
</code></pre>

<div class="table-wrapper">
    <table class="dataframe" border="1">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>slug</th>
          <th>title</th>
          <th>source_url</th>
          <th>published_at</th>
          <th>username</th>
          <th>tabcoins</th>
          <th>comments</th>
        </tr>
        <tr>
          <th>tags</th>
          <th></th>
          <th></th>
          <th></th>
          <th></th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>pitch</th>
          <td>28</td>
          <td>28</td>
          <td>6</td>
          <td>28</td>
          <td>28</td>
          <td>28</td>
          <td>28</td>
        </tr>
        <tr>
          <th>duvida</th>
          <td>20</td>
          <td>20</td>
          <td>1</td>
          <td>20</td>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>ajuda</th>
          <td>15</td>
          <td>15</td>
          <td>1</td>
          <td>15</td>
          <td>15</td>
          <td>15</td>
          <td>15</td>
        </tr>
        <tr>
          <th>artigo</th>
          <td>5</td>
          <td>5</td>
          <td>1</td>
          <td>5</td>
          <td>5</td>
          <td>5</td>
          <td>5</td>
        </tr>
        <tr>
          <th>dica</th>
          <td>4</td>
          <td>4</td>
          <td>0</td>
          <td>4</td>
          <td>4</td>
          <td>4</td>
          <td>4</td>
        </tr>
        <tr>
          <th>sugestao</th>
          <td>4</td>
          <td>4</td>
          <td>0</td>
          <td>4</td>
          <td>4</td>
          <td>4</td>
          <td>4</td>
        </tr>
        <tr>
          <th>video</th>
          <td>4</td>
          <td>4</td>
          <td>0</td>
          <td>4</td>
          <td>4</td>
          <td>4</td>
          <td>4</td>
        </tr>
        <tr>
          <th>blog do seu ze</th>
          <td>3</td>
          <td>3</td>
          <td>0</td>
          <td>3</td>
          <td>3</td>
          <td>3</td>
          <td>3</td>
        </tr>
        <tr>
          <th>debate</th>
          <td>3</td>
          <td>3</td>
          <td>0</td>
          <td>3</td>
          <td>3</td>
          <td>3</td>
          <td>3</td>
        </tr>
        <tr>
          <th>ideia</th>
          <td>2</td>
          <td>2</td>
          <td>0</td>
          <td>2</td>
          <td>2</td>
          <td>2</td>
          <td>2</td>
        </tr>
      </tbody>
    </table>
</div>

<p>Vamos entender o tamanho médio das tags, em número de palavras, para aprimorar nosso filtro.</p>

<pre><code>def get_tag_word_size(row):
    tags = row['tags']
    if tags == "":
        return 0
    return len(tags.split(" "))

df['tag_word_size'] = df.apply(get_tag_word_size, axis=1)
df.query('tags != ""').describe()
</code></pre>

<div class="table-wrapper">
    <table class="dataframe" border="1">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>tabcoins</th>
          <th>comments</th>
          <th>tag_word_size</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>count</th>
          <td>201.000000</td>
          <td>201.000000</td>
          <td>201.000000</td>
        </tr>
        <tr>
          <th>mean</th>
          <td>3.706468</td>
          <td>6.726368</td>
          <td>2.084577</td>
        </tr>
        <tr>
          <th>std</th>
          <td>8.486955</td>
          <td>22.174078</td>
          <td>2.246733</td>
        </tr>
        <tr>
          <th>min</th>
          <td>-5.000000</td>
          <td>0.000000</td>
          <td>1.000000</td>
        </tr>
        <tr>
          <th>25%</th>
          <td>1.000000</td>
          <td>1.000000</td>
          <td>1.000000</td>
        </tr>
        <tr>
          <th>50%</th>
          <td>1.000000</td>
          <td>4.000000</td>
          <td>1.000000</td>
        </tr>
        <tr>
          <th>75%</th>
          <td>3.000000</td>
          <td>6.000000</td>
          <td>3.000000</td>
        </tr>
        <tr>
          <th>max</th>
          <td>82.000000</td>
          <td>301.000000</td>
          <td>16.000000</td>
        </tr>
      </tbody>
    </table>
</div>

<p><strong>2 palavras</strong> parece ser um bom ponto de corte, visto que 50% das tags encontradas se encaixa nesse valor.</p>

<pre><code>plot_data =  df.query('tags != "" and tag_word_size &gt; 0 and tag_word_size &lt;= 2') \
.groupby('tags') \
.count() \
.reset_index() \
.sort_values(
    by=['title'],
    ascending=False
)
</code></pre>

<h3>Visualização de tags em gráfico de barras</h3>

<p>Uma forma boa de visualizar essa distribuição é com um gráfico de barras horizontal.</p>

<pre><code>%matplotlib inline

tags = plot_data['tags']
count = plot_data['title']

y_pos = np.arange(len(count))

fig = plt.figure(figsize=(6,14))
ax = fig.add_subplot()
hbars = ax.barh(y_pos, count, align='center',alpha=0.4)

ax.set_yticks(y_pos, labels=tags)
ax.invert_yaxis()  # labels read top-to-bottom
ax.set_xlabel('Quantidade')
ax.set_title('Tags vs Quantidade de ocorrências')

ax.bar_label(hbars)
ax.set_xlim(right=max(count) +5)
plt.show()
</code></pre>

<p><img src="./imgs/tags-distribution-fs8.png" alt="Distribuição de tags por número de ocorrência" title="Distribuição de tags por número de ocorrência" /></p>

<p>O gráfico nos dá uma boa visão geral da distribuição, mas como muitas tags aparecem uma única vez, e poucas tags aparecem muitas vezes, uma visão espacial pode nos dar um insight melhor sobre a frequência do seu uso.</p>

<p>Vamos gerar duas wordclouds: uma com apenas tags de uma palavra e, na segunda, vamos permitir tags de até duas palavras.</p>

<h3>Wordcloud com tags de uma única palavra</h3>

<p>Vamos alimentar as tags existentes, filtrando as que possuem uma única palavra.</p>

<pre><code>from wordcloud import WordCloud, STOPWORDS
</code></pre>

<p>A lib wordcloud espera uma string contendo a totalidade das palavras, e usa o espaço como delimitador.</p>

<pre><code>text = " ".join(df.query('tag_word_size == 1')['tags'])

wordcloud = WordCloud(
    width= 3000,
    height = 2000,
    random_state=1,
    background_color='salmon',
    colormap='Pastel1',
    collocations=False,
    stopwords = STOPWORDS
).generate(text)

plt.figure(figsize=(40, 30))
plt.imshow(wordcloud)
plt.axis("off");
</code></pre>

<p><img src="./imgs/wordcloud-one-word-tags-small-fs8.png" alt="Wordcloud usando apenas tags de uma palavra" title="Wordcloud usando apenas tags de uma palavra" /></p>

<h2>Distribuição temporal das postagens</h2>

<p>Vamos entender como foi a distribuição dos posts ao longo do tempo.</p>

<p>Primeiro, podemos usar o campo <code>published_at</code> para visualizar os posts em função dos dias da semana.</p>

<pre><code>df['day_of_week'] = df['published_at'].dt.day_name()
df['day_number'] = df['published_at'].dt.dayofweek
df[['title', 'published_at', 'username', 'day_of_week', 'day_number']].head()
</code></pre>

<div class="table-wrapper">
<table class="dataframe" border="1">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>published_at</th>
      <th>username</th>
      <th>day_of_week</th>
      <th>day_number</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Imersão Dev - Aula 1 | Expandindo os Conhecime...</td>
      <td>2023-02-01 00:14:05.054000+00:00</td>
      <td>TheDevick</td>
      <td>Wednesday</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Desenvolvedor React em início de carreira</td>
      <td>2023-02-01 00:24:06.537000+00:00</td>
      <td>kevensouzz</td>
      <td>Wednesday</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10 dicas simples para melhorar como programado...</td>
      <td>2023-02-01 00:45:36.761000+00:00</td>
      <td>roneydc</td>
      <td>Wednesday</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1 - Vamos falar sobre linguangem orientada a o...</td>
      <td>2023-02-01 00:56:42.643000+00:00</td>
      <td>roneydc</td>
      <td>Wednesday</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2 - Um pequeno exemplo de orientação a objeto ...</td>
      <td>2023-02-01 01:07:57.051000+00:00</td>
      <td>roneydc</td>
      <td>Wednesday</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>

<p>O campo <code>day_number</code> vai ser usado para ordenar nossos resultados mais pra frente.</p>

<p>Rodando localmente, poderiamos usar o argumento <code>locale="pt_BR.utf8</code> pra receber as datas em português, mas o notebook do kaggle parece não ter esse padrão instalado. Vamos fazer um ajuste.</p>

<pre><code>weekdays_ptbr = {
    "Monday": "Segunda-feira",
    "Tuesday": "Terça-feira",
    "Wednesday": "Quarta-feira",
    "Thursday": "Quinta-feira",
    "Friday": "Sexta-feira",
    "Saturday": "Sábado",
    "Sunday": "Domingo"
}
df = df.replace({"day_of_week": weekdays_ptbr})
</code></pre>

<p>E agora podemos plotar a distribuição dos posts pelos dias da semana.</p>

<pre><code>sorted_df = df.sort_values(by='day_number', ascending=True)

sorted_df.day_of_week.value_counts()[sorted_df.day_of_week.unique()] \
.plot(kind="bar")

plt.xticks(rotation=45)
</code></pre>

<p>Repare no <code>sort_values(by='day_numer')</code>. Como o campo é numérico, conseguimos uma ordenação que seria muito mais complicada usando o nome dos dias.</p>

<p><img src="./imgs/posts-by-weekday.png" alt="Distribuição dos posts por dia de semana" title="Distribuição dos posts por dia de semana" /></p>

<p>Vemos um aumento nas postagens no meio da semana, e uma acalmada no fds... é como se a galera gostasse de usar o fórum em horário de trabalho. Será?</p>

<h3>Distribuição por horário do dia</h3>

<p>Vamos começar removendo os posts de final de semana.</p>

<pre><code>df_weekdays = df.query('day_of_week != "Domingo" and day_of_week != "Sábado"')
</code></pre>

<p>Vamos pegar a hora de cada postagem, e ordenar de forma crescente (do 0 até 23).</p>

<pre><code>df_weekdays['post_time'] = df_weekdays['published_at'].dt.hour
df_weekdays = df_weekdays.sort_values(by='post_time', ascending=True)
</code></pre>

<p>Agora, agrupamos pelo número de postagens por hora e plotamos num gráfico de barras.</p>

<pre><code>df_weekdays.post_time.value_counts()[df_weekdays.post_time.unique()] \
.plot(kind="bar")
plt.xticks(rotation=45)
</code></pre>

<p><img src="./imgs/posts-by-hour.png" alt="Distribuição dos posts por hora do dia" title="Distribuição dos posts por hora do dia" /></p>

<p>Temos um pico as 14h da tarde, seguidos por uma crescente entre as 16h e as 20h.</p>

<h2>Conclusões e referências</h2>

<p>Com uma análise básica, restrita ao título das postagens e comentários, podemos compreender alguns aspectos do comportamento dos usuários do fórum.</p>

<p>Uma análise mais profunda pode estimar valores como:</p>

<ul>
<li>o melhor horário para postagens (em termos de comentários recebidos)</li>
<li>as tags com maior receptividade pelos usuários</li>
<li>os assuntos com maior engajamento na plataforma</li>
</ul>

<p>que são métricas poderosas e podem qualificar a audiência pra quem busca expandir seu público através do fórum.</p>

<p>Convido desenvolvedores com maior familiaridade na análise e manipulação dos dados a dar sequência nessa modesta análise que eu iniciei.</p>

<p>Abraço!</p>

<p>Referências:</p>

<ul>
<li><a href="https://www.tabnews.com.br/GabrielSozinho/documentacao-da-api-do-tabnews">https://www.tabnews.com.br/GabrielSozinho/documentacao-da-api-do-tabnews</a></li>
<li><a href="https://github.com/TeoMeWhy/TabNewsLake">https://github.com/TeoMeWhy/TabNewsLake</a></li>
<li><a href="https://www.kaggle.com/datasets/hacker-news/hacker-news-posts/code">https://www.kaggle.com/datasets/hacker-news/hacker-news-posts/code</a></li>
</ul>

<p>Tags: <a href='tag_python.html'>python</a>, <a href='tag_pandas.html'>pandas</a>, <a href='tag_data-science.html'>data-science</a></p>
<!-- text end -->
]]></description><link>https://guilhermegarcia.dev/blog/analise-de-conteudo-tabnews-fevereiro-de-2023.html</link>
<guid>https://guilhermegarcia.dev/blog/./analise-de-conteudo-tabnews-fevereiro-de-2023.html</guid>
<dc:creator>Guilherme Garcia</dc:creator>
<pubDate>Mon, 20 Mar 2023 21:55:00 -0300</pubDate></item>
<item><title>
Servidor HTTP com netcat e bash
</title><description><![CDATA[

<p><abbr title="muito grande; nem li">mg;nl</abbr>: Escrevi um relato dos meus estudos tentando criar um servidor com o comando <code>netcat</code> e outras ferramentas básicas do terminal, que consiga lidar com requisições GET, POST e validar o corpo das requisições.</p>

<p>Como parte de um projeto de fim de semana, precisei criar um servidor HTTP. Como estou estudando o uso da linha de comandos e scripts em bash, achei digno tentar criar um servidor que processasse o protocolo http "do zero" usando ferramentas básicas do terminal, como <code>netcat</code>, <code>read</code>, <code>mkfifo</code>, <code>sed</code>, <code>cut</code> e outros.</p>

<p>Dei uma pesquisada e achei projetos bem avançados, como o <a href="https://github.com/dfletcher/tsws">totally simple web server</a>, mas nenhum deles tinha suporte para requisições POST, para envio de informações mais complexas.</p>

<p>Decidi por fazer minha implementação com o seguinte escopo:</p>

<ol>
<li>O servidor deve processar HTTP na versão 1.1.</li>
<li>O servidor deve lidar com requisições GET e POST, e deve ser estensível para outros verbos http (PUT, PATCH, DELETE...) sem muita alteração na lógica.</li>
<li>O servidor deve ser capaz de processar o corpo das requisições e retornar respostas dinâmicas, com regra de negócio customizável.</li>
</ol>

<p>Como prova de conceito, implementei um endpoint GET que retorna um status de sucesso e um endpoint POST que recebe uma URL e verifica se ela é um link válido.</p>

<p>Você pode ver o código completo <a href="https://gist.github.com/guites/904b7ead024fbd4a2a48a769434a44f8">neste gist</a>.</p>

<hr/>
<p>Tags: <a href='tag_bash.html'>bash</a>, <a href='tag_http.html'>http</a></p>
]]></description><link>https://guilhermegarcia.dev/blog/servidor-http-com-netcat-e-bash.html</link>
<guid>https://guilhermegarcia.dev/blog/./servidor-http-com-netcat-e-bash.html</guid>
<dc:creator>Guilherme Garcia</dc:creator>
<pubDate>Sun, 12 Mar 2023 18:55:18 -0300</pubDate></item>
<item><title>
O mínimo para manter a sanidade com tabs no vim
</title><description><![CDATA[

<p>Eu adoro quando vou fazer algo que é pra ser simples e acabo saindo horrorizado com as possibilidades. </p>

<p>O vim é o melhor exemplo de algo que pode ser customizado de tantos jeitos, que 90% das soluções pra qualquer problema envolvem scripts bizarros e key maps alienígenas, que funcionam pra pessoas específicas (a pessoa que inventou, no momento em que inventou, com a chance de funcionar diminuindo pra ela mesma em função do tempo) e falham para todo o resto de forma desastrosa.</p>

<p>Tópico de hoje: tabs. Especificamente, como criar, fechar, criar uma tab a partir de um buffer e <strong>gasp</strong> mesclar duas tabs em um só buffer.</p>

<hr/>
<p>Tags: <a href='tag_vim.html'>vim</a></p>
]]></description><link>https://guilhermegarcia.dev/blog/o-minimo-para-manter-a-sanidade-com-tabs-no-vim.html</link>
<guid>https://guilhermegarcia.dev/blog/./o-minimo-para-manter-a-sanidade-com-tabs-no-vim.html</guid>
<dc:creator>Guilherme Garcia</dc:creator>
<pubDate>Sat, 04 Mar 2023 01:13:48 -0300</pubDate></item>
<item><title>
Optando pelo fork
</title><description><![CDATA[

<p>Open source é uma faca de dois gumes: você libera seu código fonte pro mundo, e todos podem inspecionar, aprender e interagir com a sua criação.</p>

<p>Isso cria uma expectativa nos usuários, a ideia de que você deve dar suporte pra correção de bugs, implementação de novas funcionalidades, e manter seu software atualizado e seguro.</p>

<p>Mas isso não é verdade: subir um projeto no github com uma licensa aberta, criar uma documentação boa e mesmo colocar um guideline pra contribuição não criam nenhum vínculo de responsabilidade.</p>

<p>O criador de um projeto aberto não é obrigado a nada.</p>

<p><a href="https://en.wikipedia.org/wiki/Feature_creep">Feature creep</a> é um conceito que costuma ser utilizado nesses casos, quando um produto tem uma diversidade muito grande de usuários, e o criador acaba tentando espandir suas funcionalidades pra suprir cada uso-caso individual.</p>

<p>Muito pior, porém, é a <a href="https://en.wikipedia.org/wiki/Job_creep">responsability creep</a>, que costuma acontecer em situações de empregador-empregado, onde uma pessoa eficiente no que faz acaba sempre recebendo mais e mais demandas.</p>

<p>No ambiente corporativo, a saída é relativamente direta: se você ganhou mais responsabilidades, exija um aumento.</p>

<p>E no open source? Ninguém pode te impedir de ser um otário, mas se você notar que os mantenedores do projeto não estão resolvendo o seu problema, siga os 3 Fs: <a href="https://boyter.org/posts/the-three-f-s-of-open-source/">fix it, fork it or fuck off</a>.</p>

<p>Em projetos menores esse comportamento ocorre em sua melhor forma: a pessoa pedindo alteração geralmente propõe a solução com um pull request.</p>

<p>Então, se você acompanha algum projeto que foi abandonado, e se viu precisando de alguma alteração, que tal criar um fork?</p>

<p>Tags: <a href='tag_open-source.html'>open-source</a>, <a href='tag_git.html'>git</a>, <a href='tag_github.html'>github</a></p>

<!-- text end -->
]]></description><link>https://guilhermegarcia.dev/blog/optando-pelo-fork.html</link>
<guid>https://guilhermegarcia.dev/blog/./optando-pelo-fork.html</guid>
<dc:creator>Guilherme Garcia</dc:creator>
<pubDate>Sun, 26 Feb 2023 15:10:15 -0300</pubDate></item>
<item><title>
Usando submódulos do git em pipelines do Azure DevOps
</title><description><![CDATA[

<p>Este post explica como configurar o uso de git submodules em pipelines de CI/CD no Azure DevOps.</p>

<p>Em específico, como configurar quando os <strong>submódulos fazem parte do mesmo projeto</strong>.</p>

<p>A solução envolve habilitar o "Checkout submodules" pelo painel do Azure, utilizar URLs relativas no arquivo .gitmodules e adicionar uma chave "resources" no arquivo .yaml da sua pipeline.</p>

<hr/>
<p>Tags: <a href='tag_azure.html'>azure</a>, <a href='tag_git.html'>git</a>, <a href='tag_ci.html'>ci</a></p>
]]></description><link>https://guilhermegarcia.dev/blog/usando-submodulos-do-git-em-pipelines-do-azure-devops.html</link>
<guid>https://guilhermegarcia.dev/blog/./usando-submodulos-do-git-em-pipelines-do-azure-devops.html</guid>
<dc:creator>Guilherme Garcia</dc:creator>
<pubDate>Thu, 23 Feb 2023 18:27:10 -0300</pubDate></item>
<item><title>
Symlinking python3 for vim on macOS
</title><description><![CDATA[

<p>Managing binaries in macos can be a shitshow, even with the assistance of great projects like <a href="https://brew.sh/">brew</a>.</p>

<p>One of brew's <a href="https://github.com/Homebrew/brew/issues/9285">most</a> <a href="https://docs.brew.sh/FAQ#why-does-brew-upgrade-formula-or-brew-install-formula-also-upgrade-a-bunch-of-other-stuff">debatable</a> feature is that installing a new package will, by default, trigger an automatic update of all existing packages. And this break things.</p>

<p>By installing some package I don't really remember the name, I ended up updating my python3 version, or rather, installing a new one, Python 3.11 .</p>

<p>This broke my beloved vim workflow :'( which uses <a href="https://github.com/psf/black">Black</a> for formatting (by running <code>:Black</code> inside vim) </p>

<p>So if you're on macOS running into the following error when running <code>:Black</code> from inside vim:</p>

<pre><code>    Error detected while processing /Users/guilhermegarcia/.vim/plugged/black/autoload/black.vim:
    line  214:
    Traceback (most recent call last):
      File "&lt;string&gt;", line 113, in &lt;module&gt;
      File "&lt;string&gt;", line 89, in _initialize_black_env
      File "/opt/homebrew/Cellar/python@3.11/3.11.1/Frameworks/Python.framework/Versions/3.11/lib/python3.11
    /venv/__init__.py", line 468, in create
        builder.create(env_dir)
      File "/opt/homebrew/Cellar/python@3.11/3.11.1/Frameworks/Python.framework/Versions/3.11/lib/python3.11
    /venv/__init__.py", line 74, in create
        self.setup_python(context)
      File "/opt/homebrew/Cellar/python@3.11/3.11.1/Frameworks/Python.framework/Versions/3.11/lib/python3.11
    /venv/__init__.py", line 292, in setup_python
        copier(context.executable, path)
      File "/opt/homebrew/Cellar/python@3.11/3.11.1/Frameworks/Python.framework/Versions/3.11/lib/python3.11
    /venv/__init__.py", line 235, in symlink_or_copy
        shutil.copyfile(src, dst)
      File "/opt/homebrew/Cellar/python@3.11/3.11.1/Frameworks/Python.framework/Versions/3.11/lib/python3.11
    /shutil.py", line 256, in copyfile
        with open(src, 'rb') as fsrc:
             ^^^^^^^^^^^^^^^
    FileNotFoundError: [Errno 2] No such file or directory: '/opt/homebrew/opt/python@3.11/Frameworks/Python
    .framework/Versions/3.11/bin/python3'
    Error detected while processing function black#Black:
    line   10:
    Traceback (most recent call last):
      File "&lt;string&gt;", line 1, in &lt;module&gt;
    NameError: name 'Black' is not defined
    Press ENTER or type command to continue
</code></pre>

<p>Turns out that somewhere, the psf/black plugin is trying to access a python binary that just isn't there:</p>

<pre><code>    guites@macos ~ % ls -l /opt/homebrew/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/bin/python3
    ls: /opt/homebrew/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/bin/python3: No such file or directory
</code></pre>

<p>It is actually at <code>/opt/homebrew/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/bin/python3.11</code> (notice the <code>.11</code>)</p>

<p>So the most straightforward fix I've found is just creating a link between the non existing binary name and the correct python installation:</p>

<pre><code>    ln /opt/homebrew/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/bin/python3.11 /opt/homebrew/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/bin/python3
</code></pre>

<p>And from there on, it should just work. Inside vim:</p>

<pre><code>    :Black

    Please wait, one time setup for Black.

    Creating a virtualenv in /Users/guilhermegarcia/.vim/black...
    (this path can be customized in .vimrc by setting g:black_virtualenv)
    Installing Black with pip...
    DONE! You are all set, thanks for waiting ✨ 🍰 ✨
    Pro-tip: to upgrade Black in the future, use the :BlackUpgrade command and restart Vim.
    Black: already well formatted, good job. (took 0.0057s)
    Press ENTER or type command to continue
</code></pre>

<p>Neat! You can safely remove the symlink (<code>unlink /opt/homebrew/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/bin/python3</code>) after this step, but its not necessary.</p>

<p>For reference, I'm running vim 9.0 with <a href="https://github.com/junegunn/vim-plug">vim-plug</a>, and installed Black by adding the following lines to my .vimrc:</p>

<pre><code>    call plug#begin('~/.vim/plugged')

    Plug 'psf/black', { 'branch': 'stable' }

    call plug#end()
</code></pre>

<p>Some other links that didn't solve my problem:</p>

<ul>
<li><a href="https://github.com/psf/black/issues/2876">https://github.com/psf/black/issues/2876</a></li>
<li><a href="https://github.com/psf/black/issues/2503">https://github.com/psf/black/issues/2503</a></li>
<li><a href="https://github.com/psf/black/issues/2547">https://github.com/psf/black/issues/2547</a></li>
<li><a href="https://github.com/psf/black/issues/1379">https://github.com/psf/black/issues/1379</a></li>
<li><a href="https://stackoverflow.com/questions/36001966/unable-to-run-python-3-after-homebrew-installation">https://stackoverflow.com/questions/36001966/unable-to-run-python-3-after-homebrew-installation</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-fix-python-no-such-file-or-directory-compiler-errors-when-installing-packages">https://www.digitalocean.com/community/tutorials/how-to-fix-python-no-such-file-or-directory-compiler-errors-when-installing-packages</a></li>
</ul>

<p>Tags: <a href='tag_vim.html'>vim</a>, <a href='tag_cli.html'>cli</a>, <a href='tag_python.html'>python</a>, <a href='tag_macos.html'>macos</a></p>





<!-- text end -->
]]></description><link>https://guilhermegarcia.dev/blog/symlinking-python3-for-vim-on-macos.html</link>
<guid>https://guilhermegarcia.dev/blog/./symlinking-python3-for-vim-on-macos.html</guid>
<dc:creator>Guilherme Garcia</dc:creator>
<pubDate>Tue, 21 Feb 2023 07:22:20 -0300</pubDate></item>
<item><title>
Remova os gifs do medium
</title><description><![CDATA[

<p>A plataforma medium tem muito conteúdo bom, mas infelizmente muitas postagens ótimas são permeadas de gifs super coloridos, que eu considero distrativos.</p>

<p>Quando eu tô procurando direcionamento sobre um tópico, e finalmente acho um post sobre o assunto, eu não gosto muito da mudança de tom que os gifs trazem, inseridos a cada parágrafo, tipo um comic relief desnecessário (<a href="https://www.google.com/search?channel=fs&amp;client=ubuntu&amp;q=jar+jar+binks">ahem</a>).</p>

<p>Daí esse snippet esconde todos os gifs e põe um botãozinho pra mostrar/esconder, aí você pode dar uma olhada e desligar a coisa.</p>

<p><img src="./imgs/remova-os-gifs-do-medium/adding-bookmarklet.png" alt="Aba dos favoritos no firefox" title="Aba dos favoritos no firefox" /></p>

<p>Você pode ir "Add Bookmarks" e adicionar o seguinte, com um nome tipo "hide-medium-gifs":</p>

<pre><code>    javascript:(function() {const doc_imgs=document.querySelectorAll('img');function toggleImgVisibility(e){let prevSibling=e.target.previousElementSibling;while(prevSibling){if(prevSibling.classList.contains('hidden-g0f')){if(prevSibling.style.visibility=='hidden'){prevSibling.style.visibility='visible';}else{prevSibling.style.visibility='hidden';}break;}prevSibling=prevSibling.previousElementSibling;}}function createToggleBtn(){const button=document.createElement("BUTTON");button.innerText="Toggle gif visibility";button.addEventListener("click",toggleImgVisibility);return button;}doc_imgs.forEach((img) =&gt; {if (!img.src.includes('.gif')) return;img.classList.add("hidden-g0f");img.style.visibility = "hidden";img.parentElement.appendChild(createToggleBtn());});}())
</code></pre>

<p>Daí, em qualquer página do medium (por <a href="https://medium.com/perry-street-software-engineering/clean-api-architecture-2b57074084d5">exemplo...</a>), basta clicar no favorito criado, e pronto: gifs pausáveis.</p>

<p><video controls style="width:100%;height:100%;"src="./imgs/remova-os-gifs-do-medium/hide-g0fs.mp4"></p>

<p>Abaixo eu explico melhor a função.</p>

<hr/>
<p>Tags: <a href='tag_bookmarklet.html'>bookmarklet</a></p>
]]></description><link>https://guilhermegarcia.dev/blog/remova-os-gifs-do-medium.html</link>
<guid>https://guilhermegarcia.dev/blog/./remova-os-gifs-do-medium.html</guid>
<dc:creator>Guilherme Garcia</dc:creator>
<pubDate>Thu, 15 Dec 2022 20:27:42 -0300</pubDate></item>
<item><title>
Sempre pode suas redes
</title><description><![CDATA[

<p>Sério, sempre pode suas redes. Docker networks abandonadas, desligadas de qualquer container podem destruir sua internet.</p>

<p>Eu fiquei duas semanas com problema na internet da minha máquina: por algum motivo, na rede de casa, a conexão do ubuntu ficava falhando.</p>

<p>Hora penava pra resolver DNSs, hora parava de funcionar completamente. Mas às vezes (geralmente quando eu pedia ajuda) ela funcionava.</p>

<p>Tentei desabilitar o IPV6 nas configurações de rede, desinstalar o <code>systemd-resolved</code>, mexer com o network manager, editar o /etc/resolv.conf diretamente.</p>

<p>Nada.</p>

<p>Em outras redes, na casa de amigos, na cafeteria, a internet funcionava. Eu cheguei a achar que meu provedor estava de sacanagem.</p>

<p>Até que tive que ficar num airBnb, e o problema voltou.</p>

<p>Olhei pro roteador, e era o mesmo <code>d-link</code> que eu tinha em casa. Já comecei a desenvolver uma crendice.</p>

<p>Acabou que não pude ir até o fim, pois um dia rodei um <code>docker network ls</code> e notei que tinha muita coisa na listagem.</p>

<pre><code>    docker network prune
    &gt;Yes
</code></pre>

<p>E problema resolvido.</p>

<p>Se alguém souber mais sobre isso, ou como reproduzir o problema, por favor, <a href="mailto:gui.garcia67@gmail.com">entre em contato</a>.</p>

<p>Mas lembre-se: sempre pode suas redes.</p>

<p>Tags: <a href='tag_docker.html'>docker</a>, <a href='tag_dns.html'>dns</a>, <a href='tag_networking.html'>networking</a></p>






<!-- text end -->
]]></description><link>https://guilhermegarcia.dev/blog/sempre-pode-suas-redes.html</link>
<guid>https://guilhermegarcia.dev/blog/./sempre-pode-suas-redes.html</guid>
<dc:creator>Guilherme Garcia</dc:creator>
<pubDate>Wed, 23 Nov 2022 16:39:35 -0300</pubDate></item>
<item><title>
Making home of the WSL 2
</title><description><![CDATA[

<p>Having recently migrated from Ubuntu to Windows as my work machine, many of the features that made my system feel like home were missing.</p>

<p>This post serves as a collection of solutions I found (and some I've adapted) from the web. Cheers!</p>

<hr/>
<p>Tags: <a href='tag_windows.html'>windows</a>, <a href='tag_wsl.html'>wsl</a></p>
]]></description><link>https://guilhermegarcia.dev/blog/making-home-of-the-wsl-2.html</link>
<guid>https://guilhermegarcia.dev/blog/./making-home-of-the-wsl-2.html</guid>
<dc:creator>Guilherme Garcia</dc:creator>
<pubDate>Tue, 22 Nov 2022 12:21:09 -0300</pubDate></item>
<item><title>
House cleaning com git
</title><description><![CDATA[

<p>Nesse post eu quero compartilhar com vocês algumas operações que eu tive que realizar em uns repositórios antigos, que estavam mal gerenciados e abandonados, pra que eu pudesse voltar a desenvolver neles.</p>

<p>As coisas que eu precisei aprender a fazer foram as seguintes:</p>

<ul>
<li>Listar autores de um repositório</li>
<li>Filtrar os commits do repositório por autor, pra ver o que cada um contribuiu</li>
<li>Relacionar combinações de autores/email diferentes de um mesmo usuário (usando o arquivo <code>.mailmap</code>)</li>
<li>Em um commit, ver quais arquivos foram alterados</li>
<li>Ver o que foi alterado em um arquivo específico dentro de um commit</li>
<li>Verificar o histórico de alteração de um arquivo no repositório (git log arquivo.js)</li>
<li>Alterar o nome e autor de alguns commits, utilizando o <a href="https://github.com/newren/git-filter-repo">git-filter-repo</a></li>
</ul>

<p>Essas tarefas são ótimas pra se familiarizar (ou relembrar) com o andamento de um projeto, ver o ritmo das alterações, quantas mudanças costumam ser embaladas num mesmo commit, e criar um feeling sobre o perfil dos desenvolvedores de um projeto.</p>

<p>Também servem pra organizar e arrumar o histórico e os meta dados dos commits passados, e por isso eu chamo de "House cleaning".</p>

<hr/>
<p>Tags: <a href='tag_git.html'>git</a></p>
]]></description><link>https://guilhermegarcia.dev/blog/house-cleaning-com-git.html</link>
<guid>https://guilhermegarcia.dev/blog/./house-cleaning-com-git.html</guid>
<dc:creator>Guilherme Garcia</dc:creator>
<pubDate>Mon, 14 Nov 2022 10:59:55 -0300</pubDate></item>
</channel></rss>
